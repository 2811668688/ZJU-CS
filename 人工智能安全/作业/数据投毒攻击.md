# 数据投毒攻击 课后思考

## 问题一

**干净标签投毒和脏标签投毒各有什么优缺点？前者一定比后者好吗？**

**干净标签投毒**：干净标签投毒方法，是运用在原始（像素）构成上和label A的数据相近，但是在某层特征空间中和label B的的特征相近的投毒数据，从而导致模型错误判断的攻击方法。其**优点**有如下几点：

- 难以检测：干净标签投毒攻击更难被模型或防御者检测到。因为干净标签投毒攻击没有明显的噪声或失真，攻击数据与原始数据非常相似。难以在数据清洗之中被发现。

- 具有可塑性：攻击者可以通过调整投毒数据的噪声强度、范围和方向等参数，从而使得攻击具有更好的适应性和可塑性。制造的变化较强。

- 攻击面广泛：干净标签投毒攻击可以用于任何类型的机器学习模型和任务，包括计算机视觉、语音识别、自然语言处理等多个领域。这使得攻击者可以在不同场景下使用干净标签投毒攻击来实施攻击。

其**缺点**有如以下的几点：

- 对攻击者要求高：干净标签投毒攻击需要攻击者具有一定的领域专业知识和技术水平，要求了解模型，在选择特征空间、评估攻击效果等方面有所理解。其制造往往不如随机翻转这样的方法简单

- 要求大量标记数据：干净标签投毒攻击需要攻击者拥有大量的带标记（即有良好的标签）的训练数据，才能制造出有效的攻击样本。如果攻击者没有足够的标记数据，那么攻击的效果可能会很差，容易被防御。

- 需要对模型理解高：因为前提条件里，要对某层特征空间有充足的理解，所以是白盒攻击，这一点较难以实现

  

**脏标签投毒攻击**，可以通过注入大量的脏标签数据来扰乱模型的训练过程，使模型产生严重的偏差和误判，从而达到控制模型、干扰模型应用、破坏模型稳定性的目的。和干净标签的方法不一样，它不改变样本，而是直接改变样本的标签。其**优点**有如下几点：

- 攻击方法灵活：有许多方法制造脏标签，如课堂上讲解过的：“基于标签反转”、“基于优化的数据投毒”、“基于梯度的数据投毒”等许多方法
- 对模型灵活：既有白盒攻击，对模型充足理解，通过训练，例如梯度下降法，来制造较好的投毒数据；也可以做黑盒攻击，比如标签反转，来进行攻击
- 对目标灵活：不强求进行有目标攻击，可以做无目标攻击，并且制造大量的错误数据来干扰模型

其**缺点**有以下几点：

- 容易被检测和清洗：脏标签攻击注入的标签数据与真实数据分布不一致，且其分布规律通常很难与真实数据相似，这使得它容易被一些有效的检测和防御方法所察觉和抵御，被数据清洗。

- 攻击效果不稳定：由于脏标签攻击是通过注入带有误导性的标签数据来干扰模型，其攻击效果往往是受数据分布、数据量、标签噪声等多种因素影响的，攻击效果不稳定；
- 误伤率高：脏标签攻击阈值较低，容易对整个训练集造成影响，导致误伤率较高，影响模型的整体性能表现；



**二者对比：**

​	前者肯定不是永远比后者好的，我列举了几条我思考的原因：

- 攻击者若对目标模型的结构和特征不了解，无法设计有针对性的干净标签攻击，但可以进行大规模的脏标签攻击
- 攻击者若希望直接突破目标模型的防御策略，脏标签攻击可以通过注入数量众多、分布复杂的标签数据来完成这个步骤。
- 若数据清洗能力弱，前者能够以较为低廉的成本来完成攻击的目标。

   而随着数据清洗的能力进一步加强，干净标签则能够提供更为隐蔽，更为目标明确的一种投毒攻击，实现攻击者的目的，而不至于引起模型运行者的直接怀疑

**总结：**

   总之，要随着情况，动态选择攻击的方法，尽管近些年来干净标签攻击越来越热门，但并不代表脏标签攻击就已经完全失去了效用。



## 问题二

**基于K-NN的中毒数据检测有什么优缺点？这种检测方法对于干净标签数据投毒和脏标签数据投毒攻击都有效吗？**

​	基于K-NN的中毒数据检测是一种基于邻近度的异常检测方法，其主要思想是通过计算每个样本点与其最近的K个邻居之间的距离来判断该样本点是否为异常点。下面先对方法的优缺点做一个概述：

**优点**：

- 检测效果较好，当K选择恰当时，能够检测出大部分的中毒数据。

- 算法较为直观，该方法是基于邻近点的欧式距离计算，并且算法思路数清晰
- 当清戏掉大部分数据后，就可以进行正确的判断

**缺点**：

- KNN方法对高维数据会碰到维度灾难的问题，在高维数据集上可能会失效或者效果较差。

- KNN方法可能会受到噪声数据的干扰，从而导致误判率增加。

**效能：**

​	对于干净标签数据投毒攻击，该方法能够有效地检测出其中的异常点，并准确地识别出中毒数据。但对于脏标签数据投毒攻击，该方法的效果可能会受到一定的影响，并且检测结果可能不够准确。这主要是因为，在脏标签数据投毒攻击中，攻击者注入的标签数据通常会与原始标签数据有很大的差异，噪声过多，从而导致样本点之间距离计算的不准确性，影响了中毒数据的检测。

**总结：**

​	总之，尽管基于K-NN的方法具有一些优缺点和应用局限性，但仍然是一种比较经典、有效的异常检测方法，可以在一定程度上应用于中毒数据的检测和预防。



## 问题三

**为了防范数据投毒攻击，你还能想到什么样的方法来提前预防这类恶意攻击对模型的可用性和完整性产生破坏？**

​	这里我结合课堂上给出的三个方向，写一些自己额外学习的到的方法

**基于数据清洗：**

- 基于先验的经验理论：对于一个模型，有一些先前就已经约定俗成的数据规则，比如出现了A特征时一定不会是B的label，那么可以引入规则，对数据进行快速的预清洗
- 基于孤立森林（Isolation Forest）方法：通过基于树结构的异常检测算法，可以快速识别出数据集中的离群点或异常值
- 基于去噪自编码器（Denoising Autoencoder）方法：通过学习输入数据的重构特征，来过滤掉数据中的无用信息和噪声。

**基于鲁棒训练的防御：**

- 梯度掩码（Gradient Masking）：通过限制梯度信息的泄漏来提高模型的鲁棒性，从而增加对抗样本攻击的难度。具体地，可以使用掩码函数来对梯度信息进行控制，从而使得在反向传播时无法准确地计算梯度。例如，在语音识别领域中，可以使用梯度掩码技术来保护声学模型不受对抗样本攻击的威胁。
- 去偏移化训练（Debiased Training）：通过解决模型的数据偏移问题，提高模型对抗攻击的鲁棒性。具体地，可以通过样本重新加权或者样本重采样等方法来降低数据分布偏移的影响，从而提高模型性能。例如，在医疗领域中，可以使用去偏移化训练技术来解决数据分布偏移的问题，提高深度学习模型对医疗数据的精度和稳定性
- 随机深度神经网络（Randomized Smoothing）：通过在输入数据周围添加噪声来减少对抗样本攻击的影响。具体地，通过将输入数据传入多个随机加噪模型并对输出结果取平均值，即可减小模型对噪声数据的敏感程度。
- 对比度增强（Contrastive Learning）：该方法通过最大化正样本和负样本之间的差异性和相似性，生成更加丰富的特征表示，提高模型的鲁棒性和泛化能力。

**基于数据增强的防御：**

- 随机擦除（Random Erasing）：通过在训练数据中随机选择一些区域并将其删除，从而强制模型学习数据的不可变性和局部区域能力。

  