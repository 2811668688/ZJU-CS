{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d020b95f-a8a0-45dc-947f-60528de2f0a3",
   "metadata": {},
   "source": [
    "# Load Cora Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8102014-13f7-4e59-a3a6-79224f5089f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cpu')\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "data = torch.load('data.pth')\n",
    "g = data['g'].to(device)\n",
    "feat = data['feat'].to(device)\n",
    "label = data['label'].to(device)\n",
    "train_nodes = data['train_nodes']\n",
    "val_nodes = data['val_nodes']\n",
    "test_nodes = data['test_nodes']\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "setup_seed(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6702618-71b5-4021-8e79-194d97d0e56c",
   "metadata": {},
   "source": [
    "# Median GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac17c03",
   "metadata": {},
   "source": [
    "*Chen et al.* [üìùUnderstanding Structural Vulnerability in Graph Convolutional Networks](https://www.ijcai.org/proceedings/2021/310), *IJCAI'21*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858f8fd8-3aa0-4e20-a555-b7a727e0f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import dgl.ops as ops\n",
    "from dgl import DGLError\n",
    "\n",
    "def dgl_normalize(g: dgl.DGLGraph, norm: str = 'both', edge_weight=None):\n",
    "    e_norm = torch.ones(g.num_edges(), device=g.device) if edge_weight is None else edge_weight\n",
    "\n",
    "    if norm == 'none':\n",
    "        return e_norm\n",
    "\n",
    "    if edge_weight is None:\n",
    "        src_degrees = g.in_degrees().clamp(min=1)\n",
    "        dst_degrees = g.out_degrees().clamp(min=1)\n",
    "    else:\n",
    "        # a weighted graph\n",
    "        src_degrees = dst_degrees = ops.copy_e_sum(g, edge_weight)\n",
    "    if norm == 'left':\n",
    "        # A * D^-1\n",
    "        norm_src = 1.0 / src_degrees\n",
    "        e_norm = ops.e_mul_v(g, e_norm, norm_src)\n",
    "    elif norm == 'right':\n",
    "        # D^-1 * A\n",
    "        norm_dst = 1.0 / dst_degrees\n",
    "        e_norm = ops.e_mul_u(g, e_norm, norm_dst)\n",
    "    else:  # both or square\n",
    "        if norm == 'both':\n",
    "            # D^-0.5 * A * D^-0.5\n",
    "            pow = -0.5\n",
    "        else:\n",
    "            # D^-1 * A * D^-1\n",
    "            pow = -1\n",
    "        norm_src = torch.pow(src_degrees, pow)\n",
    "        norm_dst = torch.pow(dst_degrees, pow)\n",
    "        e_norm = ops.e_mul_u(g, e_norm, norm_src)\n",
    "        e_norm = ops.e_mul_v(g, e_norm, norm_dst)\n",
    "    return e_norm\n",
    "\n",
    "class MedianConv(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_feats,\n",
    "                 out_feats,\n",
    "                 norm='none',\n",
    "                 activation=None,\n",
    "                 weight=True,\n",
    "                 bias=True):\n",
    "\n",
    "        super().__init__()\n",
    "        if norm not in ('none', 'both', 'right', 'left'):\n",
    "            raise DGLError('Invalid norm value. Must be either \"none\", \"both\", \"right\" or \"left\".'\n",
    "                           ' But got \"{}\".'.format(norm))\n",
    "        self._in_feats = in_feats\n",
    "        self._out_feats = out_feats\n",
    "        self._norm = norm\n",
    "        self._activation = activation\n",
    "\n",
    "        if weight:\n",
    "            self.weight = nn.Parameter(torch.Tensor(in_feats, out_feats))\n",
    "        else:\n",
    "            self.register_parameter('weight', None)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_feats))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"\n",
    "        Description\n",
    "        -----------\n",
    "        Reinitialize learnable parameters.\n",
    "        Note\n",
    "        ----\n",
    "        The model parameters are initialized as in the\n",
    "        `original implementation <https://github.com/tkipf/gcn/blob/master/gcn/layers.py>`__\n",
    "        where the weight :math:`W^{(l)}` is initialized using Glorot uniform initialization\n",
    "        and the bias is initialized to be zero.\n",
    "        \"\"\"\n",
    "        if self.weight is not None:\n",
    "            nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, graph, feat):\n",
    "        graph = graph.local_var()\n",
    "\n",
    "        edge_weight = dgl_normalize(graph, self._norm)\n",
    "        graph.edata['_edge_weight'] = edge_weight\n",
    "\n",
    "        if self.weight is not None:\n",
    "            feat = feat @ self.weight\n",
    "\n",
    "        graph.ndata['h'] = feat\n",
    "        graph.update_all(fn.u_mul_e('h', '_edge_weight', 'm'),\n",
    "                         median_reduce)\n",
    "        feat = graph.ndata.pop('h')\n",
    "\n",
    "        if self.bias is not None:\n",
    "            feat = feat + self.bias\n",
    "\n",
    "        if self._activation is not None:\n",
    "            feat = self._activation(feat)\n",
    "        return feat\n",
    "\n",
    "    def extra_repr(self):\n",
    "        \"\"\"Set the extra representation of the module,\n",
    "        which will come into effect when printing the model.\n",
    "        \"\"\"\n",
    "        summary = 'in={_in_feats}, out={_out_feats}'\n",
    "        summary += ', normalization={_norm}'\n",
    "        if '_activation' in self.__dict__:\n",
    "            summary += ', activation={_activation}'\n",
    "        return summary.format(**self.__dict__)\n",
    "\n",
    "\n",
    "def median_reduce(nodes):\n",
    "    return {'h': torch.median(nodes.mailbox['m'], dim=1).values}\n",
    "\n",
    "\n",
    "class MedianGCN(nn.Module):\n",
    "    \"\"\"Graph Convolution Network (GCN) with Median aggregation function\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    # MedianGCN with one hidden layer\n",
    "    >>> model = MedianGCN(100, 10, hid=32)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_feats: int,\n",
    "                 out_feats: int,\n",
    "                 hid: list = 16,\n",
    "                 dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.conv1 = MedianConv(in_feats, hid)\n",
    "        self.conv2 = MedianConv(hid, out_feats)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, g, feat):\n",
    "\n",
    "        if torch.is_tensor(g):\n",
    "            feat = self.dropout(feat)\n",
    "            feat = g @ (feat @ self.conv1.weight) + self.conv1.bias\n",
    "            feat = F.relu(feat)\n",
    "            feat = self.dropout(feat)\n",
    "            feat = g @ (feat @ self.conv2.weight) + self.conv2.bias\n",
    "            return feat\n",
    "        \n",
    "        g = g.add_self_loop()\n",
    "            \n",
    "        feat = self.dropout(feat)\n",
    "        feat = self.conv1(g, feat)\n",
    "        feat = F.relu(feat)\n",
    "        feat = self.dropout(feat)\n",
    "        feat = self.conv2(g, feat)\n",
    "        return feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9e2e909-2662-4b7b-a2e3-b8c6ccb629ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train: 0.2702, Val: 0.2369, Test: 0.2399\n",
      "Epoch: 002, Train: 0.4194, Val: 0.3936, Test: 0.3959\n",
      "Epoch: 003, Train: 0.5040, Val: 0.4498, Test: 0.4482\n",
      "Epoch: 004, Train: 0.5282, Val: 0.4578, Test: 0.4658\n",
      "Epoch: 005, Train: 0.5242, Val: 0.4819, Test: 0.4668\n",
      "Epoch: 006, Train: 0.5040, Val: 0.4900, Test: 0.4673\n",
      "Epoch: 007, Train: 0.5081, Val: 0.4900, Test: 0.4673\n",
      "Epoch: 008, Train: 0.5161, Val: 0.4900, Test: 0.4673\n",
      "Epoch: 009, Train: 0.5121, Val: 0.4900, Test: 0.4673\n",
      "Epoch: 010, Train: 0.5282, Val: 0.4900, Test: 0.4673\n",
      "Epoch: 011, Train: 0.5605, Val: 0.4900, Test: 0.4673\n",
      "Epoch: 012, Train: 0.5766, Val: 0.4980, Test: 0.4834\n",
      "Epoch: 013, Train: 0.6008, Val: 0.5181, Test: 0.5025\n",
      "Epoch: 014, Train: 0.6452, Val: 0.5582, Test: 0.5272\n",
      "Epoch: 015, Train: 0.6694, Val: 0.5783, Test: 0.5558\n",
      "Epoch: 016, Train: 0.7056, Val: 0.6225, Test: 0.5951\n",
      "Epoch: 017, Train: 0.7339, Val: 0.6827, Test: 0.6242\n",
      "Epoch: 018, Train: 0.7460, Val: 0.7108, Test: 0.6449\n",
      "Epoch: 019, Train: 0.7581, Val: 0.7269, Test: 0.6680\n",
      "Epoch: 020, Train: 0.7782, Val: 0.7349, Test: 0.6886\n",
      "Epoch: 021, Train: 0.7903, Val: 0.7510, Test: 0.7072\n",
      "Epoch: 022, Train: 0.7984, Val: 0.7631, Test: 0.7188\n",
      "Epoch: 023, Train: 0.8185, Val: 0.7631, Test: 0.7188\n",
      "Epoch: 024, Train: 0.8427, Val: 0.7751, Test: 0.7455\n",
      "Epoch: 025, Train: 0.8589, Val: 0.7871, Test: 0.7565\n",
      "Epoch: 026, Train: 0.8669, Val: 0.7992, Test: 0.7752\n",
      "Epoch: 027, Train: 0.8790, Val: 0.8233, Test: 0.7948\n",
      "Epoch: 028, Train: 0.8992, Val: 0.8233, Test: 0.7948\n",
      "Epoch: 029, Train: 0.9073, Val: 0.8313, Test: 0.8154\n",
      "Epoch: 030, Train: 0.9234, Val: 0.8434, Test: 0.8224\n",
      "Epoch: 031, Train: 0.9194, Val: 0.8474, Test: 0.8275\n",
      "Epoch: 032, Train: 0.9194, Val: 0.8554, Test: 0.8300\n",
      "Epoch: 033, Train: 0.9234, Val: 0.8635, Test: 0.8355\n",
      "Epoch: 034, Train: 0.9234, Val: 0.8675, Test: 0.8365\n",
      "Epoch: 035, Train: 0.9315, Val: 0.8675, Test: 0.8365\n",
      "Epoch: 036, Train: 0.9435, Val: 0.8675, Test: 0.8365\n",
      "Epoch: 037, Train: 0.9435, Val: 0.8675, Test: 0.8365\n",
      "Epoch: 038, Train: 0.9435, Val: 0.8675, Test: 0.8365\n",
      "Epoch: 039, Train: 0.9435, Val: 0.8715, Test: 0.8360\n",
      "Epoch: 040, Train: 0.9476, Val: 0.8715, Test: 0.8360\n",
      "Epoch: 041, Train: 0.9476, Val: 0.8795, Test: 0.8410\n",
      "Epoch: 042, Train: 0.9516, Val: 0.8835, Test: 0.8431\n",
      "Epoch: 043, Train: 0.9556, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 044, Train: 0.9597, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 045, Train: 0.9597, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 046, Train: 0.9677, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 047, Train: 0.9637, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 048, Train: 0.9677, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 049, Train: 0.9718, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 050, Train: 0.9718, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 051, Train: 0.9718, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 052, Train: 0.9718, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 053, Train: 0.9718, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 054, Train: 0.9758, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 055, Train: 0.9758, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 056, Train: 0.9798, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 057, Train: 0.9798, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 058, Train: 0.9798, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 059, Train: 0.9839, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 060, Train: 0.9879, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 061, Train: 0.9919, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 062, Train: 0.9879, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 063, Train: 0.9879, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 064, Train: 0.9879, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 065, Train: 0.9879, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 066, Train: 0.9879, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 067, Train: 0.9879, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 068, Train: 0.9919, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 069, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 070, Train: 0.9919, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 071, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 072, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 073, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 074, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 075, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 076, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 077, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 078, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 079, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 080, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 081, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 082, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 083, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 084, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 085, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 086, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 087, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 088, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 089, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 090, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 091, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 092, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 093, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 094, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 095, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 096, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 097, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 098, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 099, Train: 0.9960, Val: 0.8876, Test: 0.8436\n",
      "Epoch: 100, Train: 0.9960, Val: 0.8876, Test: 0.8436\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss_fn(model(g, feat)[train_nodes], label[train_nodes]).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits, accs = model(g, feat), []\n",
    "    for nodes in (train_nodes, val_nodes, test_nodes):\n",
    "        pred = logits[nodes].max(1)[1]\n",
    "        acc = pred.eq(label[nodes]).float().mean()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "device = torch.device('cpu')\n",
    "g = g.to(device)\n",
    "feat = feat.to(device)\n",
    "label = label.to(device)\n",
    "\n",
    "num_feats = feat.size(1)\n",
    "num_classes = int(label.max() + 1)\n",
    "model = MedianGCN(num_feats, num_classes).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    dict(params=model.conv1.parameters(), weight_decay=5e-4),\n",
    "    dict(params=model.conv2.parameters(), weight_decay=0)\n",
    "], lr=0.01)  # Only perform weight-decay on first convolution.\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_acc = test_acc = 0\n",
    "for epoch in range(1, 101):\n",
    "    train()\n",
    "    train_acc, val_acc, tmp_test_acc = test()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        test_acc = tmp_test_acc\n",
    "    print(f'Epoch: {epoch:03d}, Train: {train_acc:.4f}, '\n",
    "          f'Val: {best_val_acc:.4f}, Test: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e69ab69-3582-4e63-afbb-3298cfcea202",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad493aa6-f905-47f1-82d5-055d696d6b10",
   "metadata": {},
   "source": [
    "The model can be evaluated using attacked graph `attack_g` generated by different attacks. \n",
    "Just using\n",
    "```python\n",
    "\n",
    "prediction = model(attack_g, feat)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd6cbc8-2f63-4784-80b3-e5bf61481821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedianGCN(\n",
       "  (conv1): MedianConv(in=1433, out=16, normalization=none, activation=None)\n",
       "  (conv2): MedianConv(in=16, out=7, normalization=none, activation=None)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.load('attack_graph.pth')\n",
    "attack_g = d['attack_g']\n",
    "attack_feat = d['attack_feat']\n",
    "target = 1\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f231830-02ed-4c89-80ac-5ff03375a0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(g, feat)[target].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "418dced2-4d35-4bdb-b97b-3c77141a3fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target gets correctly classified\n",
    "model(attack_g, attack_feat)[target].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f88ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
